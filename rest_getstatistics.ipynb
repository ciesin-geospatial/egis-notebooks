{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from arcgis.gis import GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'statistics': [{'min': 0, 'max': 8972.0625, 'mean': 2226.154531946176, 'standardDeviation': 2508.575092466757, 'median': 598.1375, 'mode': 0, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0, 'max': 5943.0625, 'mean': 902.1668471995546, 'standardDeviation': 1262.9922955858558, 'median': 0, 'mode': 0, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0, 'max': 23.078125, 'mean': 0.7215633083989065, 'standardDeviation': 2.985524884598739, 'median': 0, 'mode': 0, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0, 'max': 9.918212890625e-05, 'mean': 1.7389695579997767e-05, 'standardDeviation': 1.359583727354395e-05, 'median': 1.4780081954656863e-05, 'mode': 7.390040977328431e-06, 'skipX': 1, 'skipY': 1, 'count': 3089016}]}\n",
      "{'statistics': [{'min': 0, 'max': 116.390625, 'mean': 12.83871389416638, 'standardDeviation': 18.863950329165817, 'median': 3.651470588235294, 'mode': 0, 'skipX': 1, 'skipY': 1, 'count': 3088862}]}\n",
      "{'statistics': [{'min': 0, 'max': 366, 'mean': 129.84700887818926, 'standardDeviation': 153.374629617807, 'median': 2.8705882352941177, 'mode': 0, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0.015625, 'max': 1, 'mean': 0.8898087926149896, 'standardDeviation': 0.22055908290846357, 'median': 1, 'mode': 1, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0, 'max': 24443.0625, 'mean': 3985.7251486091395, 'standardDeviation': 5806.467598002192, 'median': 766.8411764705883, 'mode': 0, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0, 'max': 27472.5, 'mean': 5693.213421002243, 'standardDeviation': 6753.371390450743, 'median': 3232.0588235294117, 'mode': 0, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 42618.3125, 'max': 100217.75, 'mean': 88293.89180271476, 'standardDeviation': 8160.231038996094, 'median': 90279.02352941176, 'mode': 90730.7838235294, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0, 'max': 0.01495361328125, 'mean': 0.0003809945302826326, 'standardDeviation': 0.0011195510209147809, 'median': 0, 'mode': 0, 'skipX': 1, 'skipY': 1, 'count': 10910831}]}\n",
      "{'statistics': [{'min': 0, 'max': 0.01499982236418873, 'mean': 0.005727185522183583, 'standardDeviation': 0.004372851589742513, 'median': 0.00511758645366439, 'mode': 0, 'skipX': 1, 'skipY': 1, 'count': 9386522}]}\n",
      "{'statistics': [{'min': 51275.8125, 'max': 102480.5, 'mean': 96636.93916499836, 'standardDeviation': 9543.694772947147, 'median': 100472.47303921569, 'mode': 100874.07843137256, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 6.103515625e-05, 'max': 0.01971435546875, 'mean': 0.007390894977400895, 'standardDeviation': 0.005810984910942452, 'median': 0.005456064261642157, 'mode': 6.103515625e-05, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 6.103515625e-05, 'max': 0.02001953125, 'mean': 0.00761878579380165, 'standardDeviation': 0.006014859767740653, 'median': 0.005539838005514706, 'mode': 6.103515625e-05, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 14.625, 'max': 99.4375, 'mean': 81.75054862920285, 'standardDeviation': 13.237815177228875, 'median': 82.80759803921568, 'mode': 80.47941176470587, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 217.890625, 'max': 307.09375, 'mean': 278.38395991406145, 'standardDeviation': 20.426386332126476, 'median': 280.85753676470586, 'mode': 298.3483455882353, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 216.3203125, 'max': 307.3984375, 'mean': 278.2678250831415, 'standardDeviation': 20.66169953583537, 'median': 281.32509191176473, 'mode': 299.18354779411766, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 217.078125, 'max': 298.3671875, 'mean': 274.6708509433492, 'standardDeviation': 19.122315230193287, 'median': 277.00888480392155, 'mode': 296.1357230392157, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 216.9921875, 'max': 300.4609375, 'mean': 276.469340460412, 'standardDeviation': 19.806244704072274, 'median': 278.85726102941175, 'mode': 296.86032475490197, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 211.78125, 'max': 404.296875, 'mean': 293.8025208012431, 'standardDeviation': 38.379748543157774, 'median': 287.27757352941177, 'mode': 254.0591911764706, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0.1953125, 'max': 63.3125, 'mean': 18.89544447742161, 'standardDeviation': 15.019188611257725, 'median': 14.056341911764706, 'mode': 0.1953125, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 209.8046875, 'max': 310.84375, 'mean': 278.63463384724605, 'standardDeviation': 21.56509897394217, 'median': 281.52261029411767, 'mode': 299.3530330882353, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0, 'max': 360, 'mean': 183.5525203668441, 'standardDeviation': 95.81659038320409, 'median': 189.1764705882353, 'mode': 278.11764705882354, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0, 'max': 360, 'mean': 183.42436881906866, 'standardDeviation': 95.91174903758345, 'median': 187.76470588235296, 'mode': 278.11764705882354, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0, 'max': 360, 'mean': 183.6556458191354, 'standardDeviation': 95.66028879184691, 'median': 189.1764705882353, 'mode': 279.5294117647059, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0.5, 'max': 18.375, 'mean': 6.351286386253022, 'standardDeviation': 2.2987465129563667, 'median': 6.177941176470588, 'mode': 6.738725490196079, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 0, 'max': 15.078125, 'mean': 5.158249912089467, 'standardDeviation': 2.1372668175603176, 'median': 5.203431372549019, 'mode': 5.262561274509804, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n",
      "{'statistics': [{'min': 1.171875, 'max': 20.0625, 'mean': 7.634531811928857, 'standardDeviation': 2.4639608086246785, 'median': 7.098345588235294, 'mode': 6.727941176470588, 'skipX': 1, 'skipY': 1, 'count': 10916640}]}\n"
     ]
    }
   ],
   "source": [
    "test = 'Get Statistics'\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "base_url = 'https://gis.earthdata.nasa.gov/image/rest/services/POWER/POWER_901_ANNUAL_METEOROLOGY_UTC/ImageServer'\n",
    "stats_url = base_url + '/statistics'\n",
    "multi_url = base_url + '/multidimensionalInfo?f=pjson'\n",
    "\n",
    "multi_get = requests.get(multi_url)\n",
    "multi_content = multi_get.json()\n",
    "variables = multi_content['multidimensionalInfo']['variables']\n",
    "names = [var.get('name') for var in variables]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for var in names:\n",
    "    params = {\n",
    "        'variable': var,\n",
    "        'f': 'json'\n",
    "    }\n",
    "\n",
    "    # Run the request\n",
    "    response = requests.get(stats_url, params)\n",
    "    stat_content = response.json()\n",
    "    print(stat_content)\n",
    "            \n",
    "# Calculate the cell run time\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "        \n",
    "length = len(names)\n",
    "\n",
    "# Export details to a CSV file\n",
    "with open('stats_logs.csv', mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Check if the file is empty to write headers\n",
    "    if file.tell() == 0:\n",
    "        writer.writerow(['TimeStamp', 'Test', 'Num Variables', 'Service Name', 'Cell Run Time'])\n",
    "    writer.writerow([timestamp, test, length, 'POWER_901_ANNUAL_METEOROLOGY_UTC', runtime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Image Servers: 175 \n",
      "\n",
      "Number of Image Servers with POWER in the name: 14 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "portal_url = 'https://gis.earthdata.nasa.gov/portal'\n",
    "gis = GIS(portal_url) #anonymous user\n",
    "search_result = gis.content.search(query=\"\",item_type=\"Imagery Layer\", max_items=1000)\n",
    "\n",
    "print(\"Number of Image Servers:\", len(search_result),\"\\n\")\n",
    "\n",
    "# Extract the URLs of the ImageServer layers\n",
    "image_server_urls = []\n",
    "image_server_name = []\n",
    "for item in search_result:\n",
    "    if item.url:\n",
    "        if 'Server' in item.url:\n",
    "            image_server_name.append(item.title)\n",
    "            image_server_urls.append(item.url)\n",
    "combined_list = list(zip(image_server_urls, image_server_name))\n",
    "\n",
    "# convert combined list to data frame\n",
    "image_server_df = pd.DataFrame(combined_list, columns=['URL', 'Name'])\n",
    "image_server_df\n",
    "\n",
    "# extract to search for POWER in df name\n",
    "power_df = image_server_df[image_server_df['Name'].str.contains(\"POWER\")]\n",
    "power_df\n",
    "print(\"Number of Image Servers with POWER in the name:\", len(power_df),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(base_url, name):\n",
    "    '''\n",
    "        TODO: Write function summary\n",
    "        Inputs:\n",
    "        Outputs:\n",
    "    '''\n",
    "    test = 'Get Statistics'\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    stats_url = base_url + '/statistics'\n",
    "    multi_url = base_url + '/multidimensionalInfo?f=pjson'\n",
    "\n",
    "    try:\n",
    "        multi_get = requests.get(multi_url)\n",
    "        multi_content = multi_get.json()\n",
    "        variables = multi_content['multidimensionalInfo']['variables']\n",
    "        names = [var.get('name') for var in variables]\n",
    "        length = len(names)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for var in names:\n",
    "            params = {\n",
    "                'variable': var,\n",
    "                'f': 'json'\n",
    "            }\n",
    "\n",
    "            # Run the request\n",
    "            response = requests.get(stats_url, params)\n",
    "            stat_content = response.json()\n",
    "            print(stat_content)\n",
    "            \n",
    "        # Calculate the cell run time\n",
    "        end_time = time.time()\n",
    "        runtime = end_time - start_time\n",
    "        \n",
    "        print(f'Fishing running get statistics for {name}')\n",
    "        \n",
    "        # Export details to a CSV file\n",
    "        with open('stats_logs.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            # Check if the file is empty to write headers\n",
    "            if file.tell() == 0:\n",
    "                writer.writerow(['Start Time', 'Test', 'Num Variables', 'Service Name', 'Cell Run Time'])\n",
    "            writer.writerow([start_time, test, length, name, runtime])\n",
    "    \n",
    "    except(json.JSONDecoder, KeyError) as e:\n",
    "        print(f\"Error decoding JSON or accessing key: {e} for {name}\")\n",
    "        print('Starting single variable statistics retrieval')\n",
    "        \n",
    "        # Reset the start time for single variable histogram retrieval\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Set the file output to JSON\n",
    "        params = {\n",
    "            'f': 'json'\n",
    "        }\n",
    "        \n",
    "        # Run request\n",
    "        response = requests.get(stats_url, params)\n",
    "        \n",
    "        # calculate the cell run time\n",
    "        end_time = time.time()\n",
    "        runtime = end_time - start_time # Total cell run time\n",
    "        \n",
    "        # Export details to a CSV file\n",
    "        with open('stats_logs.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            # Check if the file is empty to write headers\n",
    "            if file.tell() == 0:\n",
    "                writer.writerow(['Start Time', 'Test', 'Num Variables', 'Base URL', 'Cell Run Time'])\n",
    "            writer.writerow([start_time, test, '1', name, runtime])\n",
    "            \n",
    "        print(f'Finished running single histogram request for {stats_url}')\n",
    "        return\n",
    "    \n",
    "    print('Finished returning all histograms')\n",
    "    \n",
    "    return 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "catching classes that do not inherit from BaseException is not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mget_samples\u001b[1;34m(base_url, name)\u001b[0m\n\u001b[0;32m     10\u001b[0m multi_content \u001b[38;5;241m=\u001b[39m multi_get\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m---> 11\u001b[0m variables \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_content\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmultidimensionalInfo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m names \u001b[38;5;241m=\u001b[39m [var\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m variables]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'multidimensionalInfo'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url, name \u001b[38;5;129;01min\u001b[39;00m combined_list:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mget_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 42\u001b[0m, in \u001b[0;36mget_samples\u001b[1;34m(base_url, name)\u001b[0m\n\u001b[0;32m     39\u001b[0m             writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum Variables\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mService Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCell Run Time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     40\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow([start_time, test, length, name, runtime])\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m(json\u001b[38;5;241m.\u001b[39mJSONDecoder, \u001b[38;5;167;01mKeyError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError decoding JSON or accessing key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting single variable statistics retrieval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: catching classes that do not inherit from BaseException is not allowed"
     ]
    }
   ],
   "source": [
    "for url, name in combined_list:\n",
    "    get_samples(base_url=url, name=name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
